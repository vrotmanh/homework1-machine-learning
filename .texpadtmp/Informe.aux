\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}DigitRecognizer}{2}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}b) Write a function to display an MNIST digit. Display one of each digit}{2}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}c) Examine the prior probability of the classes in the training data. Is it uniform across the digits? Display a normalized histogram of digit counts. Is it even?}{3}{subsection.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Histogram of digit count\relax }}{3}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{Digit Count}{{1}{3}{Histogram of digit count\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}d) Pick one example of each digit from your training data. Then, for each sample digit, compute and show the best match (nearest neighbor) between your chosen sample and the rest of the training data. Use L2 distance between the two images\IeC {\textquoteright } pixel values as the metric. This probably won\IeC {\textquoteright }t be perfect, so add an asterisk next to the erroneous examples (if any).}{3}{subsection.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}e) Consider the case of binary comparison between the digits 0 and 1. Ignoring all the other digits, compute the pairwise distances for all genuine matches and all impostor matches, again using the L2 norm. Plot histograms of the genuine and impostor distances on the same set of axes.}{5}{subsection.1.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Genuine Matches vs Impostor Matches\relax }}{5}{figure.caption.2}}
\newlabel{Genuine vs Impostor}{{2}{5}{Genuine Matches vs Impostor Matches\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}f) Generate an ROC curve from the above sets of distances. What is the equal error rate? What is the error rate of a classifier that simply guesses randomly?}{6}{subsection.1.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces ROC Curve for the sets of 0 and 1\relax }}{6}{figure.caption.3}}
\newlabel{ROC Curve}{{3}{6}{ROC Curve for the sets of 0 and 1\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}g) Implement a K-NN classifier. (You cannot use external libraries for this question; it should be your own implementation.)}{6}{subsection.1.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}h) Using the training data for all digits, perform 3 fold cross-validation on your K-NN classifier and report your average accuracy.}{6}{subsection.1.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8}i) Generate a confusion matrix (ofsize 10 x 10) from your results. Which digits are particularly tricky to classify?}{6}{subsection.1.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Confusion Matrix\relax }}{7}{figure.caption.4}}
\newlabel{Confusion Matrix}{{4}{7}{Confusion Matrix\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}The Titanic Disaster}{7}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Written Exercises}{7}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Variance of a sum. Show that the variance of a sum is $var[X-Y]=var[X] + var[Y] - 2*cov[X,Y]$, where $cov[X,Y]$ is the covariance between random variables $X$ and $Y$.}{7}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Bayes rule for quality control. You\IeC {\textquoteright }re the foreman at a factory making ten million widgets per year. As a quality control step before shipment, you create a detector that tests for defective widgets be- fore sending them to customers. The test is uniformly 95\% accurate, meaning that the probability of testing positive given that the widget is defective is 0.95, as is the probability of testing negative given that the widget is not defective. Further, only one in 100,000 widgets is actually defective.}{7}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}In k-nearest neighbors, the classification is achieved by majority vote in the vicinity of data. Sup- pose our training data comprises n data points with two classes, each comprising exactly half of the training data, with some overlap between the two classes.}{9}{subsection.3.3}}
